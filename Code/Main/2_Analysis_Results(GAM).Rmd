
---
title: "2.Analysis_Results(GAM)"
author: "Jaeseok Hwang"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: defaulta
---




## Knitr option

```{r, cache = F, echo = F, results = "hide"}
#####

library(knitr)

knitr::opts_chunk$set(
  cache = FALSE,
  echo = FALSE,
  warning = FALSE,
  cache.lazy = FALSE,
  fig.retina = 6,
  fig.height = 9,
  fig.width = 9,
  message = FALSE,
  error = TRUE
)

options(knitr.duplicate.label = "allow")

```


#### Packages 

```{r pacakages, cache = FALSE, results = "hide"}

library(here)
library(rmarkdown) # for rmarkdown options
library(jsonlite) # for json data loading and processing
library(parallel) # for parallel processing (computing)
library(bookdown) # for bookdown options
library(knitr) # for knitr options
library(stringr) # for string manipulation

library(measurements) # for unit conversion
library(data.table) # for data manipulation
library(tidyverse) # for data manipulation
library(dplyr) # for data manipulation

library(tmap) # for mapping
library(ggplot2) # for plotting

library(sf) # for spatial data
library(stars) # some raster data needs to be stacked in stars format
library(raster) # for raster data
library(exactextractr) # to extract the raster data from stacked star

library(terra) # to calculate the topographic variables
library(spatialEco) # to calculate the topographic variables
library(elevatr) # for the dem data ( digital eleveation model)
library(soilDB) # for soil survey data ( SSURGO)
library(FedData) # for soil survey data ( SSURGO)
library(daymetr) # for daymet data ( weather info)

library(mgcv) # for GAM
library(smoother) # for GAM
###################



```

# Read sources and load processed data

```{r source, echo = F, results = "hide"}

# Read functions for data processing 
source(here("Code","Main","0_Set_up_preparation.R"))
source(here("Code","Functions","functions_for_analysis.R"))

```



```{r analysis GAM, cache = T, results = "hide"}
 
### Check all the field_year list (ffy) in the processed data(Analysis_Ready) folder

ffy_merged_dat <- list.files(here("Data","Processed","Analysis_ready")) %>%
 str_subset("_merged_data.rds") %>%
   str_remove("_merged_data.rds")


ffy_weather_info <- list.files(here("Data","Processed","Analysis_ready")) %>%
 str_subset("_weather_info.rds") %>%
   str_remove("_weather_info.rds")

match(ffy_merged_dat, ffy_weather_info)


# Run and evaluate GAMs with all the considered formula
# for each experimental trial field
info_tb_list <- list()
best_gam_list <- list()

for(i in 1:length(ffy_merged_dat)) {
  
  ffy_id <- ffy_merged_dat[i]
  # Read Sf data and weather info table
  dat_sf <- readRDS(here("Data", "processed", "Analysis_ready", paste0(ffy_id, "_merged_data.rds")))
  
  dat_sf <- dat_sf %>% st_transform(4326)
 # Drop geometry and convert to data.table
  dat_tb <- dat_sf %>% st_drop_geometry() %>% as.data.table()
  
  # Get input variables containing "rate"
  input_vars <- colnames(dat_tb)[grep("rate", colnames(dat_tb))]
  
  # set field regression variables for making evaluation data
  except_s <- setdiff(colnames(dat_tb), c("s_rate", "yield", 'obs_id'))
 
# Normalize the columns
# dat_tb[, ( except_s) := lapply(.SD, function(x) (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)), .SDcols = except_s]


  # Generate all possible GAM formulas
  gam_formulas <- generate_gam_formulas(input_vars, field_reg_vars)

  # Run and evaluate GAM models
  best_formula <- run_and_evaluate_gams(gam_formulas, dat_tb)
  
  # Update info_tb with best formulas using data.table syntax


  ### predict yield values at input sequence 
   # Generate input rate sequence (100 points) 
   input_s_seq  <-  dat_tb[, .(
      s_rate = seq(
        quantile(s_rate, 0.025),
        quantile(s_rate, 0.975),
        length = 100
      )
      )]

  # generate evaluation data to predict yield values by model 
  dat_for_eval <- input_s_seq[, (except_s) := lapply(dat_tb[, .SD, .SDcols = except_s], 
    function(x) mean(x, na.rm = TRUE))]


 # predict yield by reml and gcv method based gam regression model, respectively
   # predict_yield_range(data_for_evaluation, formula)# 
 
  eval_dat  <-  predict_yield_range(best_formula$gam_best, dat_for_eval)

  # Predict and evaluate estimated profit under the given crop price and input price
  # of the trial year, year that the seed/corn price ratio is lowest (low) , 
  # and year that the seed/corn price ratio is highest (high)

  info_tb <- readRDS(here("Data", "processed", "Analysis_ready", paste0(ffy_id, "_weather_info.rds")))
   
  setnames(info_tb, "gc_rate", "sqsr")
   
   info_tb <- info_tb %>% mutate(sqsr = ifelse(sqsr >100, sqsr/1000, sqsr))

  info_tb$year <- as.numeric(str_extract(info_tb$ffy_id, "\\d{4}"))
  
  #  estimate_profit_fcn(info_table, evaluation_data, price_table)
  eval_tb  <- estimate_profit_fcn(info_tb, eval_dat, price_tab) 

  # Estimates and report  eosr and profit by eosr
  # Estimates the profit by sqsr and usdasr
   

  # Track centroid of the ofpe field 
  cent_dat <- dat_sf %>%
  st_bbox() %>%
  st_as_sfc() %>%
  st_centroid() %>%
  st_as_sf() 

   # find which state the field is located in
   cent_in_ofpe <- st_join(cent_dat, ofpe_sf, join = st_within)

  # mutate usdsr variable by taking matched fips code.
     info_tb$usdsr <- seed_usda$s_rate[seed_usda$year == info_tb$year & seed_usda$fips == cent_in_ofpe$fips]

  # mutate seeding rate info, yield and profit by seeding rate
   info_tb[, `:=`( 
   eosr = eval_tb[which.max(profit_hat_year), s_rate],
   eosr_low = eval_tb[which.max(profit_hat_low), s_rate],
   eosr_high = eval_tb[which.max(profit_hat_high), s_rate],
   eosr_y = eval_tb[which.max(profit_hat_year), yield_hat],
   eosr_y_low = eval_tb[which.max(profit_hat_low), yield_hat],
   eosr_y_high = eval_tb[which.max(profit_hat_high), yield_hat],
   eosr_p = eval_tb[which.max(profit_hat_year), profit_hat_year],
   eosr_p_low = eval_tb[which.max(profit_hat_low), profit_hat_low],
   eosr_p_high = eval_tb[which.max(profit_hat_high), profit_hat_high],
   usdsr_y = eval_tb[which.min(abs(s_rate - info_tb$usdsr)), yield_hat], 
   usdsr_p = eval_tb[which.min(abs(s_rate - info_tb$usdsr)), profit_hat_year],
   sqsr_y = eval_tb[which.min(abs(s_rate - info_tb$sqsr)), yield_hat], 
  sqsr_p = eval_tb[which.min(abs(s_rate - info_tb$sqsr)), profit_hat_year]
    )]

  # Write the updated info_tb back to file
  saveRDS(eval_tb, here("Data", "processed", "Analysis_results", paste0(ffy_id, "_eval_tb.rds")))
  saveRDS(info_tb, here("Data", "processed", "Analysis_results", paste0(ffy_id, "_info_tb.rds")))
  
  info_tb_list[[i]] <- info_tb
  best_gam_list[[i]] <- best_formula
}

 saveRDS(best_gam_list, here("Data", "Processed", "Analysis_results", "best_gam_list.rds"))
 saveRDS(info_tb_list, here("Data", "Processed", "Analysis_results", "info_tb_list.rds"))





```



